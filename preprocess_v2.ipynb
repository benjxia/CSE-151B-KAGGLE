{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-13T11:56:53.651222Z",
     "end_time": "2023-05-13T11:56:53.663507Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing, metrics\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train: pd.DataFrame = pd.read_csv(\"./data/train.csv\")\n",
    "df_test: pd.DataFrame = pd.read_csv(\"./data/test_public.csv\")\n",
    "df_meta: pd.DataFrame = pd.read_csv(\"./data/metaData_taxistandsID_name_GPSlocation.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T12:47:59.249417Z",
     "end_time": "2023-05-13T12:48:25.769296Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get starting coordinates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_row_polyline():\n",
    "    start_coords = np.zeros((len(df_train), 2))\n",
    "    end_coords = np.zeros((len(df_train), 2))\n",
    "    for i in range(len(df_train)):\n",
    "        row = ast.literal_eval(df_train.iloc[i][\"POLYLINE\"])\n",
    "        if len(row) == 0:\n",
    "            continue\n",
    "        start_coords[i] = row[0]\n",
    "        end_coords[i] = row[-1]\n",
    "    return start_coords, end_coords\n",
    "\n",
    "# start_coords, end_coords = parse_row_polyline()\n",
    "# np.save(\"start_full.npy\", start_coords)\n",
    "# np.save(\"end_full.npy\", end_coords)\n",
    "start_coords = np.load(\"start_full.npy\")\n",
    "end_coords = np.load(\"end_full.npy\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T12:31:29.822971Z",
     "end_time": "2023-05-13T12:31:29.901019Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train[\"START_LONG\"] = start_coords[:, 0]\n",
    "df_train[\"START_LAT\"] = start_coords[:, 1]\n",
    "df_train[\"END_LONG\"] = end_coords[:, 0]\n",
    "df_train[\"END_LAT\"] = end_coords[:, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T12:49:00.736097Z",
     "end_time": "2023-05-13T12:49:00.822435Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T12:54:48.633772Z",
     "end_time": "2023-05-13T12:54:48.702574Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "central_long = df_train[df_train[\"CALL_TYPE\"] == \"A\"][\"START_LONG\"].median()\n",
    "central_lat = df_train[df_train[\"CALL_TYPE\"] == \"A\"][\"START_LAT\"].median()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T12:56:18.148639Z",
     "end_time": "2023-05-13T12:56:18.486151Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Delete useless rows/Columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove rows with MISSING_DATA == true\n",
    "df_train.drop(df_train[df_train[\"MISSING_DATA\"] == True].index, inplace=True)\n",
    "df_train.drop(labels=\"MISSING_DATA\", axis=1, inplace=True)\n",
    "# Not necessary for test set\n",
    "df_test.drop(labels=\"MISSING_DATA\", axis=1, inplace=True)\n",
    "\n",
    "# Delete column DAY_TYPE\n",
    "df_train.drop(labels=\"DAY_TYPE\", axis=1, inplace=True)\n",
    "df_test.drop(labels=\"DAY_TYPE\", axis=1, inplace=True)\n",
    "\n",
    "# Delete column TRIP_ID\n",
    "df_train.drop(labels=\"TRIP_ID\", axis=1, inplace=True)\n",
    "df_test.drop(labels=\"TRIP_ID\", axis=1, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T12:58:12.292205Z",
     "end_time": "2023-05-13T12:58:14.120649Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encode categorical"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# one-hot encoding for call types\n",
    "df_train = df_train.join(pd.get_dummies(df_train[\"CALL_TYPE\"]))\n",
    "df_train.drop(labels=\"CALL_TYPE\", axis=1, inplace=True)\n",
    "\n",
    "df_test = df_test.join(pd.get_dummies(df_test[\"CALL_TYPE\"]))\n",
    "df_test.drop(labels=\"CALL_TYPE\", axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T12:58:21.629851Z",
     "end_time": "2023-05-13T12:58:23.477086Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Taxi id's -> indices\n",
    "LE_TAXI_ID = preprocessing.LabelEncoder()\n",
    "LE_TAXI_ID.fit(df_train[\"TAXI_ID\"])\n",
    "df_train[\"TAXI_ID\"] = LE_TAXI_ID.transform(df_train[\"TAXI_ID\"])\n",
    "\n",
    "df_test[\"TAXI_ID\"] = LE_TAXI_ID.transform(df_test[\"TAXI_ID\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T13:01:49.589899Z",
     "end_time": "2023-05-13T13:01:49.917489Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ORIGIN_CALL's -> indices\n",
    "df_train.at[pd.isna(df_train[\"ORIGIN_CALL\"]) == True, \"ORIGIN_CALL\"] = 0\n",
    "val_cnt = df_train[\"ORIGIN_CALL\"].value_counts().to_dict()\n",
    "df_train[\"ORIGIN_CALL\"] = df_train[\"ORIGIN_CALL\"].map(lambda x : x  if val_cnt[x] > 1 else 0 )\n",
    "\n",
    "multi_occurences = set(df_train[\"ORIGIN_CALL\"].unique())\n",
    "new_col = df_test[\"ORIGIN_CALL\"]\n",
    "for i, x in enumerate(new_col):\n",
    "    if x not in multi_occurences:\n",
    "        new_col[i] = 0\n",
    "\n",
    "df_test[\"ORIGIN_CALL\"] = new_col\n",
    "\n",
    "LE_ORIGIN_CALL = preprocessing.LabelEncoder()\n",
    "LE_ORIGIN_CALL.fit(df_train[\"ORIGIN_CALL\"])\n",
    "df_train[\"ORIGIN_CALL\"] = LE_ORIGIN_CALL.transform(df_train[\"ORIGIN_CALL\"])\n",
    "df_test[\"ORIGIN_CALL\"] = LE_ORIGIN_CALL.transform(df_test[\"ORIGIN_CALL\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T13:03:16.741412Z",
     "end_time": "2023-05-13T13:03:18.531121Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train[\"ORIGIN_CALL\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T13:04:31.831460Z",
     "end_time": "2023-05-13T13:04:31.869892Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Encode ORIGIN_STAND\n",
    "LE_ORIGIN_STAND = preprocessing.LabelEncoder()\n",
    "LE_ORIGIN_STAND.fit(df_train[\"ORIGIN_STAND\"])\n",
    "df_train[\"ORIGIN_STAND\"] = LE_ORIGIN_STAND.transform(df_train[\"ORIGIN_STAND\"])\n",
    "df_test[\"ORIGIN_STAND\"] = LE_ORIGIN_STAND.transform(df_test[\"ORIGIN_STAND\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T13:07:07.393930Z",
     "end_time": "2023-05-13T13:07:07.660520Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Datetime"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train[\"YEAR\"] = df_train[\"TIMESTAMP\"].apply(lambda x: datetime.fromtimestamp(x).year)\n",
    "df_train[\"WK_OF_YR\"] = df_train[\"TIMESTAMP\"].apply(lambda x: datetime.fromtimestamp(x).isocalendar().week)\n",
    "df_train[\"WK_DAY\"] = df_train[\"TIMESTAMP\"].apply(lambda x: datetime.fromtimestamp(x).weekday()) # WHY ARE YOU LIKE THIS??? ALL THE OTHERS ARE FIELDS\n",
    "df_train[\"HR\"] = df_train[\"TIMESTAMP\"].apply(lambda x: datetime.fromtimestamp(x).hour)\n",
    "df_train.drop(labels=\"TIMESTAMP\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df_test[\"YEAR\"] = df_test[\"TIMESTAMP\"].apply(lambda x: datetime.fromtimestamp(x).year)\n",
    "df_test[\"WK_OF_YR\"] = df_test[\"TIMESTAMP\"].apply(lambda x: datetime.fromtimestamp(x).isocalendar().week)\n",
    "df_test[\"WK_DAY\"] = df_test[\"TIMESTAMP\"].apply(lambda x: datetime.fromtimestamp(x).weekday()) # WHY ARE YOU LIKE THIS??? ALL THE OTHERS ARE FIELDS\n",
    "df_test[\"HR\"] = df_test[\"TIMESTAMP\"].apply(lambda x: datetime.fromtimestamp(x).hour)\n",
    "df_test.drop(labels=\"TIMESTAMP\", axis=1, inplace=True)\n",
    "# TODO: use timestamps for NN instead of whatever the fuck this is"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T13:05:34.232973Z",
     "end_time": "2023-05-13T13:05:42.412125Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create target column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train[\"TARGET\"] = df_train[\"POLYLINE\"].apply(lambda x : 15 * max(x.count(\"[\") - 1, 0))\n",
    "df_train.drop(labels=\"POLYLINE\", axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T13:06:06.206416Z",
     "end_time": "2023-05-13T13:06:11.043996Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T13:07:35.108395Z",
     "end_time": "2023-05-13T13:07:35.171265Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T13:08:39.149074Z",
     "end_time": "2023-05-13T13:08:39.161267Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.to_csv(\"./data/processed_trainv6.csv\", index=False)\n",
    "df_test.to_csv(\"./data/processed_testv6.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-13T13:25:16.057752Z",
     "end_time": "2023-05-13T13:25:28.084978Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Continue in `finalize.ipynb`"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
