{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T15:22:03.046106Z",
     "start_time": "2023-05-20T15:21:57.044471Z"
    }
   },
   "outputs": [],
   "source": [
    "from Indexed_Dataset import *\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:04:14.785832Z",
     "start_time": "2023-04-25T11:04:14.731012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x235685cd3d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr = np.loadtxt(\"../data/embed_trainvf.csv\", dtype=np.float32, delimiter=\",\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training/validation sets\n",
    "np.random.shuffle(train_arr)\n",
    "valid_arr = train_arr[int(0.9 * train_arr.shape[0]):]\n",
    "train_arr = train_arr[:int(0.9 * train_arr.shape[0])]\n",
    "weights = train_arr[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:04:15.775358Z",
     "start_time": "2023-04-25T11:04:14.785832Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sampler = WeightedRandomSampler(weights=weights, num_samples=train_arr.shape[0], replacement=True)\n",
    "\n",
    "train_set = Indexed_Dataset(arr=train_arr)\n",
    "train_load = DataLoader(dataset=train_set,\n",
    "                        batch_size=32,\n",
    "#                         sampler=sampler,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=g,)\n",
    "\n",
    "valid_set = Indexed_Dataset(arr=valid_arr)\n",
    "valid_load = DataLoader(dataset=valid_set,\n",
    "                        batch_size=32,\n",
    "                        # num_workers=8,\n",
    "                        shuffle=True,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=g,)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:06:37.789948Z",
     "start_time": "2023-04-25T11:06:37.758708Z"
    }
   },
   "outputs": [],
   "source": [
    "class TravelRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        origin_call_dim = 6\n",
    "        origin_stand_dim = 5\n",
    "        taxi_id_dim = 5\n",
    "        year_dim = 2\n",
    "        wk_of_yr_dim = 5\n",
    "        wk_day_dim = 5\n",
    "        hr_dim = 5\n",
    "        \n",
    "        self.embed_origin_call: nn.Module = nn.Embedding(29027, origin_call_dim)\n",
    "        self.embed_origin_stand: nn.Module = nn.Embedding(64, origin_stand_dim)\n",
    "        self.embed_taxi_id: nn.Module = nn.Embedding(448, taxi_id_dim)\n",
    "        self.embed_year: nn.Module = nn.Embedding(2, year_dim)\n",
    "        self.embed_wk_of_yr: nn.Module = nn.Embedding(52, wk_of_yr_dim)\n",
    "        self.embed_wk_day: nn.Module = nn.Embedding(7, wk_day_dim)\n",
    "        self.embed_hr: nn.Module = nn.Embedding(24, hr_dim)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(6 + \n",
    "                      origin_call_dim + \n",
    "                      origin_stand_dim + \n",
    "                      taxi_id_dim + \n",
    "                      year_dim + \n",
    "                      wk_of_yr_dim +\n",
    "                      wk_day_dim + \n",
    "                      hr_dim\n",
    "                      ,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000, 800),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(800, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        origin_call = self.embed_origin_call(input[:, 0].to(dtype=torch.int32))\n",
    "        origin_stand = self.embed_origin_stand(input[:, 1].to(dtype=torch.int32))\n",
    "        taxi_id = self.embed_taxi_id(input[:, 2].to(dtype=torch.int32))\n",
    "        year = self.embed_year(input[:, 8].to(dtype=torch.int32))\n",
    "        wk_of_year = self.embed_wk_of_yr(input[:, 9].to(dtype=torch.int32))\n",
    "        wk_day = self.embed_wk_day(input[:, 10].to(dtype=torch.int32))\n",
    "        hr = self.embed_hr(input[:, 11].to(dtype=torch.int32))\n",
    "        input = torch.cat((origin_call, \n",
    "                           origin_stand, \n",
    "                           taxi_id, \n",
    "                           input[:, 3:8],\n",
    "                           year,\n",
    "                           wk_of_year,\n",
    "                           wk_day,\n",
    "                           hr,\n",
    "                           input[:, 12:]\n",
    "                           ), dim=1).to(dtype=torch.float32)\n",
    "        input = self.feed_forward(input.to(dtype=torch.float32))\n",
    "        return input\n",
    "\n",
    "model = TravelRegressor().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:06:39.219554Z",
     "start_time": "2023-04-25T11:06:39.190938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(train_set[0][0].unsqueeze(0).to(device)).size()\n",
    "# train_set[0][0].unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_mse(pred, act):\n",
    "    denom = torch.sum(act)\n",
    "    return torch.sum(act * ((pred - act)**2 / len(act))) / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T14:02:31.352229Z",
     "start_time": "2023-04-16T14:02:31.304302Z"
    }
   },
   "outputs": [],
   "source": [
    "lossfn = nn.MSELoss(reduction=\"mean\")\n",
    "# lossfn = weight_mse\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T14:02:31.357059Z",
     "start_time": "2023-04-16T14:02:31.335915Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate():\n",
    "    lossfn_valid = nn.MSELoss(reduction=\"mean\")\n",
    "    model.eval()\n",
    "    loss = torch.tensor([0]).to(device, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        for i, (entry, target) in enumerate(valid_load):\n",
    "            entry = entry.to(device, dtype=torch.float32)\n",
    "            target = target.to(device, dtype=torch.float32)\n",
    "            preds = model(entry)\n",
    "            loss += lossfn_valid(preds, target) * entry.size()[0]\n",
    "\n",
    "    return loss / len(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T14:02:31.405736Z",
     "start_time": "2023-04-16T14:02:31.362017Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse_loss = []\n",
    "def train(num_iter: int):\n",
    "    for epoch in range(num_iter):\n",
    "        rolling_loss = 0\n",
    "        entries = 0\n",
    "        for i, (entry, target) in enumerate(train_load):\n",
    "            model.train()\n",
    "            entry = entry.to(device, dtype=torch.float32)\n",
    "            target = target.to(device, dtype=torch.float32)\n",
    "            preds = model(entry)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = lossfn(preds, target) # or weighted mse\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rolling_loss += loss * entry.size(0)\n",
    "            entries += entry.size(0)\n",
    "            if (i + 1) % 500 == 0 or i == 0:\n",
    "                rolling_loss /= entries\n",
    "                print(f\"[Epoch: {epoch + 1}]\\t[Iter: {i + 1}]\\t[RMSE: {torch.sqrt(rolling_loss)}]\")\n",
    "                print(f\"Prediction std dev: {torch.std(preds).item()}\")\n",
    "                rmse_loss.append(torch.sqrt(rolling_loss).item())\n",
    "                entries = 0\n",
    "                rolling_loss = 0\n",
    "\n",
    "        valid_loss = validate()\n",
    "        print(f\"[RMSE Validation: {torch.sqrt(valid_loss).item()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(rmse_loss)\n",
    "plt.xlabel(\"Iteration's\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test = torch.from_numpy(np.loadtxt(\"../data/embed_testvf.csv\", skiprows=1, dtype=np.float32, delimiter=\",\")).to(device)\n",
    "    out = model(test)\n",
    "    torch.set_printoptions(threshold=10000, sci_mode=False)\n",
    "    print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
