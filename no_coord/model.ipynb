{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:04:14.731012Z",
     "start_time": "2023-04-25T11:04:09.671301Z"
    }
   },
   "outputs": [],
   "source": [
    "from Indexed_Dataset import *\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:04:14.785832Z",
     "start_time": "2023-04-25T11:04:14.731012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f93646a31b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:04:15.775358Z",
     "start_time": "2023-04-25T11:04:14.785832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000000e+00 1.000000e+00 2.000000e+00 ... 1.710667e+06 1.710668e+06\n",
      " 1.710669e+06]\n"
     ]
    }
   ],
   "source": [
    "train_arr = np.loadtxt(\"../data/no_coord_train.csv\", dtype=np.float32, delimiter=\",\", skiprows=1)\n",
    "print(train_arr[:, 0])\n",
    "mean = train_arr[:, -1].mean()\n",
    "std = train_arr[:, -1].std()\n",
    "train_arr = train_arr[train_arr[:, -1] < mean + 5 * std]\n",
    "train_arr = train_arr[train_arr[:, -1] > 50]\n",
    "# Split into training/validation sets\n",
    "np.random.shuffle(train_arr)\n",
    "valid_arr = train_arr[int(0.9 * train_arr.shape[0]):]\n",
    "train_arr = train_arr[:int(0.9 * train_arr.shape[0])]\n",
    "weights = train_arr[:, -1]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=weights, num_samples=train_arr.shape[0], replacement=True)\n",
    "\n",
    "train_set = Indexed_Dataset(arr=train_arr)\n",
    "train_load = DataLoader(dataset=train_set,\n",
    "                        batch_size=32,\n",
    "#                         sampler=sampler,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=g,)\n",
    "\n",
    "valid_set = Indexed_Dataset(arr=valid_arr)\n",
    "valid_load = DataLoader(dataset=valid_set,\n",
    "                        batch_size=32,\n",
    "                        # num_workers=8,\n",
    "                        shuffle=True,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=g,)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:06:37.789948Z",
     "start_time": "2023-04-25T11:06:37.758708Z"
    }
   },
   "outputs": [],
   "source": [
    "class TravelRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        origin_call_dim = 20\n",
    "        origin_stand_dim = 5\n",
    "        taxi_id_dim = 10\n",
    "        self.embed_origin_call: nn.Module = nn.Embedding(29027, origin_call_dim, padding_idx=0)\n",
    "        self.embed_origin_stand: nn.Module = nn.Embedding(64, origin_stand_dim)\n",
    "        self.embed_taxi_id: nn.Module = nn.Embedding(448, taxi_id_dim)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(9 + origin_call_dim + origin_stand_dim + taxi_id_dim, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000, 800),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(800, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        origin_call = self.embed_origin_call(input[:, 0].to(dtype=torch.int32))\n",
    "        origin_stand = self.embed_origin_stand(input[:, 1].to(dtype=torch.int32))\n",
    "        taxi_id = self.embed_taxi_id(input[:, 2].to(dtype=torch.int32))\n",
    "        input = torch.cat((origin_call, origin_stand, taxi_id, input[:, 3:]), dim=1).to(dtype=torch.float32)\n",
    "        input = self.feed_forward(input)\n",
    "        return input\n",
    "\n",
    "model = TravelRegressor().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:06:39.219554Z",
     "start_time": "2023-04-25T11:06:39.190938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(train_set[0][0].unsqueeze(0).to(device)).size()\n",
    "# train_set[0][0].unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T14:02:31.352229Z",
     "start_time": "2023-04-16T14:02:31.304302Z"
    }
   },
   "outputs": [],
   "source": [
    "mse = nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_mse(pred, act):\n",
    "    denom = torch.sum(act)\n",
    "    return torch.sum(act * ((pred - act)**2 / len(act))) / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T14:02:31.357059Z",
     "start_time": "2023-04-16T14:02:31.335915Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    loss = torch.tensor([0]).to(device, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        for i, (entry, target) in enumerate(valid_load):\n",
    "            entry = entry.to(device, dtype=torch.float32)\n",
    "            target = target.to(device, dtype=torch.float32)\n",
    "            preds = model(entry)\n",
    "            loss += mse(preds, target)\n",
    "\n",
    "    return loss /(i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T14:02:31.405736Z",
     "start_time": "2023-04-16T14:02:31.362017Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse_loss = []\n",
    "valid_loss = []\n",
    "def train(num_iter: int):\n",
    "    for epoch in range(num_iter):\n",
    "        rolling_loss = 0\n",
    "        entries = 0\n",
    "        for i, (entry, target) in enumerate(train_load):\n",
    "            model.train()\n",
    "            entry = entry.to(device, dtype=torch.float32)\n",
    "            target = target.to(device, dtype=torch.float32)\n",
    "            preds = model(entry)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = mse(preds, target) # or weighted mse\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rolling_loss += mse(preds, target) * entry.size(0)\n",
    "            entries += entry.size(0)\n",
    "            if (i + 1) % 500 == 0 or i == 0:\n",
    "                rolling_loss /= entries\n",
    "                print(f\"[Epoch: {epoch + 1}]\\t[Iter: {i + 1}]\\t[RMSE: {torch.sqrt(rolling_loss)}]\\t[STD: {torch.std(preds).item()}]\")\n",
    "                rmse_loss.append(torch.sqrt(rolling_loss).item())\n",
    "                valid_loss.append(torch.sqrt(validate()).item())\n",
    "                entries = 0\n",
    "                rolling_loss = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1]\t[Iter: 1]\t[RMSE: 904.6311645507812]\t[STD: 1.220678687095642]\n",
      "[Epoch: 1]\t[Iter: 500]\t[RMSE: 483.912109375]\t[STD: 128.19338989257812]\n",
      "[Epoch: 1]\t[Iter: 1000]\t[RMSE: 460.364990234375]\t[STD: 102.03137969970703]\n",
      "[Epoch: 1]\t[Iter: 1500]\t[RMSE: 454.1444396972656]\t[STD: 132.04541015625]\n",
      "[Epoch: 1]\t[Iter: 2000]\t[RMSE: 445.71112060546875]\t[STD: 125.44325256347656]\n",
      "[Epoch: 1]\t[Iter: 2500]\t[RMSE: 450.5604553222656]\t[STD: 120.10313415527344]\n",
      "[Epoch: 1]\t[Iter: 3000]\t[RMSE: 455.60052490234375]\t[STD: 119.15948486328125]\n",
      "[Epoch: 1]\t[Iter: 3500]\t[RMSE: 440.59979248046875]\t[STD: 118.45662689208984]\n",
      "[Epoch: 1]\t[Iter: 4000]\t[RMSE: 446.5441589355469]\t[STD: 107.38921356201172]\n",
      "[Epoch: 1]\t[Iter: 4500]\t[RMSE: 450.65899658203125]\t[STD: 138.66151428222656]\n",
      "[Epoch: 1]\t[Iter: 5000]\t[RMSE: 442.819091796875]\t[STD: 120.94920349121094]\n",
      "[Epoch: 1]\t[Iter: 5500]\t[RMSE: 436.3639221191406]\t[STD: 132.7995147705078]\n",
      "[Epoch: 1]\t[Iter: 6000]\t[RMSE: 450.7597961425781]\t[STD: 96.7884750366211]\n",
      "[Epoch: 1]\t[Iter: 6500]\t[RMSE: 439.2449951171875]\t[STD: 132.9474639892578]\n",
      "[Epoch: 1]\t[Iter: 7000]\t[RMSE: 441.7408447265625]\t[STD: 134.47329711914062]\n",
      "[Epoch: 1]\t[Iter: 7500]\t[RMSE: 447.6513366699219]\t[STD: 108.86229705810547]\n",
      "[Epoch: 1]\t[Iter: 8000]\t[RMSE: 441.8962097167969]\t[STD: 96.51730346679688]\n",
      "[Epoch: 1]\t[Iter: 8500]\t[RMSE: 448.6590270996094]\t[STD: 150.13848876953125]\n",
      "[Epoch: 1]\t[Iter: 9000]\t[RMSE: 425.58880615234375]\t[STD: 133.25845336914062]\n",
      "[Epoch: 1]\t[Iter: 9500]\t[RMSE: 446.2388000488281]\t[STD: 133.24288940429688]\n",
      "[Epoch: 1]\t[Iter: 10000]\t[RMSE: 443.3441162109375]\t[STD: 108.19754791259766]\n",
      "[Epoch: 1]\t[Iter: 10500]\t[RMSE: 444.046142578125]\t[STD: 127.29119110107422]\n",
      "[Epoch: 1]\t[Iter: 11000]\t[RMSE: 439.78643798828125]\t[STD: 128.3992462158203]\n",
      "[Epoch: 1]\t[Iter: 11500]\t[RMSE: 436.1907653808594]\t[STD: 102.21379089355469]\n",
      "[Epoch: 1]\t[Iter: 12000]\t[RMSE: 439.2289733886719]\t[STD: 108.41565704345703]\n",
      "[Epoch: 1]\t[Iter: 12500]\t[RMSE: 443.50653076171875]\t[STD: 131.84762573242188]\n",
      "[Epoch: 1]\t[Iter: 13000]\t[RMSE: 433.78192138671875]\t[STD: 115.20144653320312]\n",
      "[Epoch: 1]\t[Iter: 13500]\t[RMSE: 439.256103515625]\t[STD: 98.18083190917969]\n",
      "[Epoch: 1]\t[Iter: 14000]\t[RMSE: 428.06036376953125]\t[STD: 121.65910339355469]\n",
      "[Epoch: 1]\t[Iter: 14500]\t[RMSE: 436.0328674316406]\t[STD: 115.53814697265625]\n",
      "[Epoch: 1]\t[Iter: 15000]\t[RMSE: 445.4764099121094]\t[STD: 191.4813690185547]\n",
      "[Epoch: 1]\t[Iter: 15500]\t[RMSE: 440.8815612792969]\t[STD: 131.12942504882812]\n",
      "[Epoch: 1]\t[Iter: 16000]\t[RMSE: 437.9857177734375]\t[STD: 150.1116485595703]\n",
      "[Epoch: 1]\t[Iter: 16500]\t[RMSE: 437.31585693359375]\t[STD: 131.40403747558594]\n",
      "[Epoch: 1]\t[Iter: 17000]\t[RMSE: 430.91973876953125]\t[STD: 144.84149169921875]\n",
      "[Epoch: 1]\t[Iter: 17500]\t[RMSE: 435.9085998535156]\t[STD: 135.87400817871094]\n",
      "[Epoch: 1]\t[Iter: 18000]\t[RMSE: 436.13873291015625]\t[STD: 170.6328582763672]\n",
      "[Epoch: 1]\t[Iter: 18500]\t[RMSE: 433.1167297363281]\t[STD: 115.55067443847656]\n",
      "[Epoch: 1]\t[Iter: 19000]\t[RMSE: 442.03436279296875]\t[STD: 141.3775634765625]\n",
      "[Epoch: 1]\t[Iter: 19500]\t[RMSE: 435.6910400390625]\t[STD: 127.21237182617188]\n",
      "[Epoch: 1]\t[Iter: 20000]\t[RMSE: 444.1749267578125]\t[STD: 134.22410583496094]\n",
      "[Epoch: 1]\t[Iter: 20500]\t[RMSE: 437.45831298828125]\t[STD: 136.93109130859375]\n",
      "[Epoch: 1]\t[Iter: 21000]\t[RMSE: 437.4364013671875]\t[STD: 129.29910278320312]\n",
      "[Epoch: 1]\t[Iter: 21500]\t[RMSE: 443.6517639160156]\t[STD: 152.97079467773438]\n",
      "[Epoch: 1]\t[Iter: 22000]\t[RMSE: 423.8902587890625]\t[STD: 125.73896789550781]\n",
      "[Epoch: 1]\t[Iter: 22500]\t[RMSE: 434.9764709472656]\t[STD: 169.89328002929688]\n",
      "[Epoch: 1]\t[Iter: 23000]\t[RMSE: 435.94805908203125]\t[STD: 151.5496063232422]\n",
      "[Epoch: 1]\t[Iter: 23500]\t[RMSE: 428.85504150390625]\t[STD: 156.05331420898438]\n",
      "[Epoch: 1]\t[Iter: 24000]\t[RMSE: 433.41717529296875]\t[STD: 138.16175842285156]\n",
      "[Epoch: 1]\t[Iter: 24500]\t[RMSE: 444.4810791015625]\t[STD: 112.76606750488281]\n",
      "[Epoch: 1]\t[Iter: 25000]\t[RMSE: 441.5740051269531]\t[STD: 112.77401733398438]\n",
      "[Epoch: 1]\t[Iter: 25500]\t[RMSE: 442.4408264160156]\t[STD: 97.25984191894531]\n",
      "[Epoch: 1]\t[Iter: 26000]\t[RMSE: 433.73895263671875]\t[STD: 170.34840393066406]\n",
      "[Epoch: 1]\t[Iter: 26500]\t[RMSE: 434.80364990234375]\t[STD: 124.19395446777344]\n",
      "[Epoch: 1]\t[Iter: 27000]\t[RMSE: 429.23529052734375]\t[STD: 139.10435485839844]\n",
      "[Epoch: 1]\t[Iter: 27500]\t[RMSE: 428.56671142578125]\t[STD: 164.75222778320312]\n",
      "[Epoch: 1]\t[Iter: 28000]\t[RMSE: 432.4064636230469]\t[STD: 106.57685852050781]\n",
      "[Epoch: 1]\t[Iter: 28500]\t[RMSE: 430.9086608886719]\t[STD: 168.7369842529297]\n",
      "[Epoch: 1]\t[Iter: 29000]\t[RMSE: 441.314453125]\t[STD: 116.97210693359375]\n",
      "[Epoch: 1]\t[Iter: 29500]\t[RMSE: 435.9071044921875]\t[STD: 128.5907440185547]\n",
      "[Epoch: 1]\t[Iter: 30000]\t[RMSE: 427.43017578125]\t[STD: 166.54161071777344]\n",
      "[Epoch: 1]\t[Iter: 30500]\t[RMSE: 427.9023132324219]\t[STD: 161.84950256347656]\n",
      "[Epoch: 1]\t[Iter: 31000]\t[RMSE: 438.9235534667969]\t[STD: 122.9761962890625]\n",
      "[Epoch: 1]\t[Iter: 31500]\t[RMSE: 431.935546875]\t[STD: 165.6539764404297]\n",
      "[Epoch: 1]\t[Iter: 32000]\t[RMSE: 447.48828125]\t[STD: 141.3079071044922]\n",
      "[Epoch: 1]\t[Iter: 32500]\t[RMSE: 431.81561279296875]\t[STD: 125.80136108398438]\n",
      "[Epoch: 1]\t[Iter: 33000]\t[RMSE: 430.05291748046875]\t[STD: 154.77676391601562]\n",
      "[Epoch: 1]\t[Iter: 33500]\t[RMSE: 431.31402587890625]\t[STD: 128.96388244628906]\n",
      "[Epoch: 1]\t[Iter: 34000]\t[RMSE: 430.3926696777344]\t[STD: 126.83382415771484]\n",
      "[Epoch: 1]\t[Iter: 34500]\t[RMSE: 428.5709228515625]\t[STD: 144.2532196044922]\n",
      "[Epoch: 1]\t[Iter: 35000]\t[RMSE: 432.7900085449219]\t[STD: 150.30221557617188]\n",
      "[Epoch: 1]\t[Iter: 35500]\t[RMSE: 427.3149108886719]\t[STD: 98.97674560546875]\n",
      "[Epoch: 1]\t[Iter: 36000]\t[RMSE: 439.22259521484375]\t[STD: 127.12958526611328]\n",
      "[Epoch: 1]\t[Iter: 36500]\t[RMSE: 446.7767639160156]\t[STD: 136.62969970703125]\n",
      "[Epoch: 1]\t[Iter: 37000]\t[RMSE: 435.6026306152344]\t[STD: 152.46304321289062]\n",
      "[Epoch: 1]\t[Iter: 37500]\t[RMSE: 432.8648681640625]\t[STD: 149.39312744140625]\n",
      "[Epoch: 1]\t[Iter: 38000]\t[RMSE: 430.81109619140625]\t[STD: 153.69068908691406]\n",
      "[Epoch: 1]\t[Iter: 38500]\t[RMSE: 430.1070251464844]\t[STD: 114.67208099365234]\n",
      "[Epoch: 1]\t[Iter: 39000]\t[RMSE: 437.3000183105469]\t[STD: 113.25525665283203]\n",
      "[Epoch: 1]\t[Iter: 39500]\t[RMSE: 431.4478759765625]\t[STD: 169.4672393798828]\n",
      "[Epoch: 1]\t[Iter: 40000]\t[RMSE: 440.08575439453125]\t[STD: 126.45330047607422]\n",
      "[Epoch: 1]\t[Iter: 40500]\t[RMSE: 426.9151916503906]\t[STD: 118.84603881835938]\n",
      "[Epoch: 1]\t[Iter: 41000]\t[RMSE: 436.84747314453125]\t[STD: 204.17079162597656]\n",
      "[Epoch: 1]\t[Iter: 41500]\t[RMSE: 433.2965087890625]\t[STD: 117.76930236816406]\n",
      "[Epoch: 1]\t[Iter: 42000]\t[RMSE: 436.332275390625]\t[STD: 173.9827117919922]\n",
      "[Epoch: 1]\t[Iter: 42500]\t[RMSE: 437.3509521484375]\t[STD: 127.32122039794922]\n",
      "[Epoch: 1]\t[Iter: 43000]\t[RMSE: 437.6920166015625]\t[STD: 160.58631896972656]\n",
      "[Epoch: 1]\t[Iter: 43500]\t[RMSE: 442.2817077636719]\t[STD: 127.57435607910156]\n",
      "[Epoch: 1]\t[Iter: 44000]\t[RMSE: 444.2575378417969]\t[STD: 184.63694763183594]\n",
      "[Epoch: 1]\t[Iter: 44500]\t[RMSE: 424.84716796875]\t[STD: 106.16851806640625]\n",
      "[Epoch: 1]\t[Iter: 45000]\t[RMSE: 436.0486755371094]\t[STD: 123.01301574707031]\n",
      "[Epoch: 1]\t[Iter: 45500]\t[RMSE: 438.1654357910156]\t[STD: 143.4015655517578]\n",
      "[Epoch: 1]\t[Iter: 46000]\t[RMSE: 435.4578857421875]\t[STD: 133.3217010498047]\n",
      "[Epoch: 1]\t[Iter: 46500]\t[RMSE: 437.0459899902344]\t[STD: 143.3411102294922]\n"
     ]
    }
   ],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(rmse_loss, label=\"training\")\n",
    "plt.plot(valid_loss, label=\"validation\")\n",
    "plt.xlabel(\"Iteration's\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426.50860595703125"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(validate()).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milestone part 3 getting top 10 data points with greatest training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = torch.from_numpy(train_arr).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3386"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "# del variables\n",
    "gc.collect()\n",
    "# Ran into CUDA out of memory :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_load = DataLoader(dataset=train_set,\n",
    "                        batch_size=32,\n",
    "#                         sampler=sampler,\n",
    "                        shuffle=False, # I just disabled shuffling\n",
    "                        num_workers=8,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=g,)\n",
    "model.eval()\n",
    "full_loss = np.zeros(len(train_set))\n",
    "total = 0\n",
    "batchsz = 0\n",
    "with torch.no_grad():\n",
    "    for i, (entry, target) in enumerate(eval_load):\n",
    "        entry = entry.to(device, dtype=torch.float32)\n",
    "        target = target.to(device, dtype=torch.float32)\n",
    "        preds = model(entry)\n",
    "        batchsz = target.size()[0]\n",
    "        full_loss[total:total + batchsz] = np.sqrt((preds.cpu().numpy() - target.cpu().numpy())**2)[:, 0]\n",
    "        total += target.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 312078 1126849  109034  135649 1436240  108166  876270  770785 1372843\n",
      " 1399250]\n",
      "[3549.31518555 3583.26391602 3594.75244141 3595.67797852 3598.5246582\n",
      " 3604.25708008 3614.87329102 3620.29956055 3669.8737793  3694.53271484]\n",
      "[ 246099.  737684. 1162019.  498709.  183950.   30871.  811174.  825096.\n",
      "  454547.  356296.]\n"
     ]
    }
   ],
   "source": [
    "order = np.argsort(full_loss)\n",
    "print(order[-10:]) # 10 worst loss data points\n",
    "print(full_loss[order[-10:]])\n",
    "print(train_arr[order[-10:], 0]) # indices in original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1710669.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_arr[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_136/1658925262.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_arr' is not defined"
     ]
    }
   ],
   "source": [
    "eval_arr[train_arr[:, 0].astype(np.int32), 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_arr = np.loadtxt(\"../data/no_coord_train.csv\", dtype=np.float32, delimiter=\",\", skiprows=1)\n",
    "eval_set = Indexed_Dataset(arr=eval_arr)\n",
    "eval_load = DataLoader(dataset=eval_set,\n",
    "                        batch_size=32,\n",
    "#                         sampler=sampler,\n",
    "                        shuffle=False, # I just disabled shuffling\n",
    "                        num_workers=8,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=g,)\n",
    "model.eval()\n",
    "full_loss = np.zeros(len(eval_set))\n",
    "total = 0\n",
    "batchsz = 0\n",
    "with torch.no_grad():\n",
    "    for i, (entry, target) in enumerate(eval_load):\n",
    "        entry = entry.to(device, dtype=torch.float32)\n",
    "        target = target.to(device, dtype=torch.float32)\n",
    "        preds = model(entry)\n",
    "        batchsz = target.size()[0]\n",
    "        full_loss[total:total + batchsz] = np.sqrt((preds.cpu().numpy() - target.cpu().numpy())**2)[:, 0]\n",
    "        total += target.size()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710660\n",
      "[38849.01953125 38992.9609375  39716.15625    43418.04296875\n",
      " 45445.9140625  52402.1328125  53240.76171875 56979.97265625\n",
      " 57086.9609375  57280.05078125]\n",
      "[1003868  849524 1199131  182827  385816  147120  224508  578577 1492407\n",
      " 1093719]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1003876.,  849531., 1199139.,  182829.,  385819.,  147121.,\n",
       "        224510.,  578581., 1492417., 1093727.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = np.argsort(full_loss)\n",
    "print(len(order))\n",
    "print(full_loss[order[-10:]])\n",
    "print(order[-10:]) # 10 worst loss data points\n",
    "eval_arr[order[-10:], 0] # indices in original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     test = torch.from_numpy(np.loadtxt(\"../data/no_coord_test.csv\", skiprows=1, dtype=np.float32, delimiter=\",\")).to(device)\n",
    "#     out = model(test)\n",
    "#     torch.set_printoptions(threshold=10000, sci_mode=False)\n",
    "#     df_pred = pd.read_csv(\"../data/sampleSubmission.csv\")\n",
    "#     df_pred[\"TRAVEL_TIME\"] = out.cpu().numpy()\n",
    "#     df_pred.to_csv(\"NN_nocoord_weighted_prune.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
