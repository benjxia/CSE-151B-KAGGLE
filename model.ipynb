{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:04:14.731012Z",
     "start_time": "2023-04-25T11:04:09.671301Z"
    }
   },
   "outputs": [],
   "source": [
    "from KGLE_Dataset import *\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:04:14.785832Z",
     "start_time": "2023-04-25T11:04:14.731012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28d769354b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = KGLE_Dataset(\"./data/embed_trainvf.csv\")\n",
    "# weights = [label for (item, label) in train_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.loadtxt(\"./data/embed_trainvf.csv\", delimiter=\",\", skiprows=1)\n",
    "weights = weights[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1495471,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WeightedRandomSampler(weights=weights, num_samples=len(train_set), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:04:15.775358Z",
     "start_time": "2023-04-25T11:04:14.785832Z"
    }
   },
   "outputs": [],
   "source": [
    "train_load = DataLoader(dataset=train_set,\n",
    "                        batch_size=32,\n",
    "#                         sampler=sampler,\n",
    "                        shuffle=True,\n",
    "                        # num_workers=8,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=g,)\n",
    "\n",
    "valid_set = KGLE_Dataset(\"./data/embed_validvf.csv\")\n",
    "valid_load = DataLoader(dataset=valid_set,\n",
    "                        batch_size=32,\n",
    "                        # num_workers=8,\n",
    "                        shuffle=True,\n",
    "                        worker_init_fn=seed_worker,\n",
    "                        generator=g,)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1495471"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:06:37.789948Z",
     "start_time": "2023-04-25T11:06:37.758708Z"
    }
   },
   "outputs": [],
   "source": [
    "class TravelRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        origin_call_dim = 6\n",
    "        origin_stand_dim = 5\n",
    "        taxi_id_dim = 5\n",
    "        year_dim = 2\n",
    "        wk_of_yr_dim = 5\n",
    "        wk_day_dim = 5\n",
    "        hr_dim = 5\n",
    "        \n",
    "        self.embed_origin_call: nn.Module = nn.Embedding(29027, origin_call_dim)\n",
    "        self.embed_origin_stand: nn.Module = nn.Embedding(64, origin_stand_dim)\n",
    "        self.embed_taxi_id: nn.Module = nn.Embedding(448, taxi_id_dim)\n",
    "        self.embed_year: nn.Module = nn.Embedding(2, year_dim)\n",
    "        self.embed_wk_of_yr: nn.Module = nn.Embedding(52, wk_of_yr_dim)\n",
    "        self.embed_wk_day: nn.Module = nn.Embedding(7, wk_day_dim)\n",
    "        self.embed_hr: nn.Module = nn.Embedding(24, hr_dim)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(6 + \n",
    "                      origin_call_dim + \n",
    "                      origin_stand_dim + \n",
    "                      taxi_id_dim + \n",
    "                      year_dim + \n",
    "                      wk_of_yr_dim +\n",
    "                      wk_day_dim + \n",
    "                      hr_dim\n",
    "                      ,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000, 800),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(800, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        origin_call = self.embed_origin_call(input[:, 0].to(dtype=torch.int32))\n",
    "        origin_stand = self.embed_origin_stand(input[:, 1].to(dtype=torch.int32))\n",
    "        taxi_id = self.embed_taxi_id(input[:, 2].to(dtype=torch.int32))\n",
    "        year = self.embed_year(input[:, 8].to(dtype=torch.int32))\n",
    "        wk_of_year = self.embed_wk_of_yr(input[:, 9].to(dtype=torch.int32))\n",
    "        wk_day = self.embed_wk_day(input[:, 10].to(dtype=torch.int32))\n",
    "        hr = self.embed_hr(input[:, 11].to(dtype=torch.int32))\n",
    "        input = torch.cat((origin_call, \n",
    "                           origin_stand, \n",
    "                           taxi_id, \n",
    "                           input[:, 3:8],\n",
    "                           year,\n",
    "                           wk_of_year,\n",
    "                           wk_day,\n",
    "                           hr,\n",
    "                           input[:, 12:]\n",
    "                           ), dim=1).to(dtype=torch.float32)\n",
    "        input = self.feed_forward(input.to(dtype=torch.float32))\n",
    "        return input\n",
    "\n",
    "model = TravelRegressor().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:06:39.219554Z",
     "start_time": "2023-04-25T11:06:39.190938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(train_set[0][0].unsqueeze(0).to(device)).size()\n",
    "# train_set[0][0].unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_mse(pred, act):\n",
    "    denom = torch.sum(act)\n",
    "    return torch.sum(act * ((pred - act)**2 / len(act))) / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T14:02:31.352229Z",
     "start_time": "2023-04-16T14:02:31.304302Z"
    }
   },
   "outputs": [],
   "source": [
    "lossfn = nn.MSELoss(reduction=\"mean\")\n",
    "# lossfn = weight_mse\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T14:02:31.357059Z",
     "start_time": "2023-04-16T14:02:31.335915Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    loss = torch.tensor([0]).to(device, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        for i, (entry, target) in enumerate(valid_load):\n",
    "            entry = entry.to(device, dtype=torch.float32)\n",
    "            target = target.to(device, dtype=torch.float32)\n",
    "            preds = model(entry)\n",
    "            loss += lossfn(preds, target)\n",
    "\n",
    "    return loss /(i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T14:02:31.405736Z",
     "start_time": "2023-04-16T14:02:31.362017Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse_loss = []\n",
    "def train(num_iter: int):\n",
    "    for epoch in range(num_iter):\n",
    "        for i, (entry, target) in enumerate(train_load):\n",
    "            model.train()\n",
    "            entry = entry.to(device, dtype=torch.float32)\n",
    "            target = target.to(device, dtype=torch.float32)\n",
    "            preds = model(entry)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = lossfn(preds, target) # or weighted mse\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 500 == 0 or i == 0:\n",
    "                print(f\"[Epoch: {epoch + 1}]\\t[Iter: {i + 1}]\\t[RMSE: {torch.sqrt(loss)}]\")\n",
    "                print(f\"Prediction std dev: {torch.std(preds).item()}\")\n",
    "\n",
    "            rmse_loss.append(torch.sqrt(loss).item())\n",
    "\n",
    "        valid_loss = validate()\n",
    "        print(f\"[RMSE Validation: {torch.sqrt(valid_loss).item()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1]\t[Iter: 1]\t[RMSE: 386.3883056640625]\n",
      "Prediction std dev: 126.34185791015625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9944/2140545206.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9944/3742503065.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(num_iter)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# or weighted mse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"[Epoch: {epoch + 1}]\\t[Iter: {i + 1}]\\t[RMSE: {torch.sqrt(loss)}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'differentiable'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             adam(params_with_grad,\n\u001b[0m\u001b[0;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m     func(params,\n\u001b[0m\u001b[0;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python39\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m                 \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Program Files\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "390886.15625"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(0, len(rmse_loss)), rmse_loss)\n",
    "plt.xlabel(\"# of 500 iteration's\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  793.8265],\n",
      "        [  774.1790],\n",
      "        [  786.9352],\n",
      "        [  793.9023],\n",
      "        [  761.6528],\n",
      "        [  796.7250],\n",
      "        [  776.7170],\n",
      "        [  820.7263],\n",
      "        [  772.2891],\n",
      "        [  778.4208],\n",
      "        [  762.7768],\n",
      "        [  777.7084],\n",
      "        [  815.2253],\n",
      "        [  798.7531],\n",
      "        [  769.3024],\n",
      "        [  798.6263],\n",
      "        [  808.4692],\n",
      "        [  809.5801],\n",
      "        [  795.8856],\n",
      "        [  789.0472],\n",
      "        [  782.7125],\n",
      "        [  786.3989],\n",
      "        [  776.8250],\n",
      "        [  818.6525],\n",
      "        [  796.7206],\n",
      "        [  827.8629],\n",
      "        [  755.8573],\n",
      "        [  768.5643],\n",
      "        [  778.2201],\n",
      "        [  769.8325],\n",
      "        [  769.6036],\n",
      "        [  787.7539],\n",
      "        [  777.0521],\n",
      "        [  775.5562],\n",
      "        [  823.1422],\n",
      "        [  774.0112],\n",
      "        [  795.5021],\n",
      "        [  771.3828],\n",
      "        [  790.1435],\n",
      "        [  777.5578],\n",
      "        [  798.2370],\n",
      "        [  775.2573],\n",
      "        [  789.4103],\n",
      "        [  831.9680],\n",
      "        [  792.9907],\n",
      "        [  790.7371],\n",
      "        [  761.3979],\n",
      "        [  792.3920],\n",
      "        [  769.0247],\n",
      "        [  769.3217],\n",
      "        [  796.3196],\n",
      "        [  790.3477],\n",
      "        [  770.6058],\n",
      "        [  857.0958],\n",
      "        [  795.2001],\n",
      "        [  769.8271],\n",
      "        [  803.2217],\n",
      "        [  781.8104],\n",
      "        [  786.7032],\n",
      "        [  779.4539],\n",
      "        [  769.7297],\n",
      "        [  783.3232],\n",
      "        [  805.6908],\n",
      "        [  801.0441],\n",
      "        [  835.3986],\n",
      "        [  787.8434],\n",
      "        [  778.4265],\n",
      "        [  769.4451],\n",
      "        [  781.8757],\n",
      "        [  815.0189],\n",
      "        [  815.2516],\n",
      "        [  767.0902],\n",
      "        [  783.7170],\n",
      "        [  773.2989],\n",
      "        [  785.0384],\n",
      "        [  792.1511],\n",
      "        [  813.0670],\n",
      "        [  802.9147],\n",
      "        [  785.7805],\n",
      "        [  784.3326],\n",
      "        [  804.9705],\n",
      "        [  787.6799],\n",
      "        [  809.5938],\n",
      "        [  795.7510],\n",
      "        [  805.2793],\n",
      "        [  807.6105],\n",
      "        [  827.1666],\n",
      "        [  799.4738],\n",
      "        [  780.9009],\n",
      "        [  833.6522],\n",
      "        [  813.2497],\n",
      "        [  796.6979],\n",
      "        [  785.5047],\n",
      "        [  843.4906],\n",
      "        [  810.8235],\n",
      "        [  782.6959],\n",
      "        [  797.6184],\n",
      "        [  840.9304],\n",
      "        [  787.1346],\n",
      "        [  810.5832],\n",
      "        [  784.2208],\n",
      "        [  784.7203],\n",
      "        [  782.6515],\n",
      "        [  811.6804],\n",
      "        [  787.9146],\n",
      "        [  791.4248],\n",
      "        [  798.7278],\n",
      "        [  777.8316],\n",
      "        [  786.8306],\n",
      "        [  814.0918],\n",
      "        [  944.7313],\n",
      "        [  824.3195],\n",
      "        [  803.5585],\n",
      "        [  815.6097],\n",
      "        [  792.2900],\n",
      "        [  779.1685],\n",
      "        [  785.2928],\n",
      "        [  784.6516],\n",
      "        [  807.4042],\n",
      "        [  830.7209],\n",
      "        [  818.9406],\n",
      "        [  804.9990],\n",
      "        [  776.0977],\n",
      "        [  789.7924],\n",
      "        [  775.8823],\n",
      "        [  831.7489],\n",
      "        [  790.8074],\n",
      "        [  859.3361],\n",
      "        [  776.1003],\n",
      "        [  801.9072],\n",
      "        [  806.3552],\n",
      "        [  791.7258],\n",
      "        [  777.2808],\n",
      "        [  814.9344],\n",
      "        [  808.4865],\n",
      "        [  785.8593],\n",
      "        [  781.6744],\n",
      "        [  793.1944],\n",
      "        [  807.4311],\n",
      "        [  797.0100],\n",
      "        [  789.1246],\n",
      "        [  778.2228],\n",
      "        [  808.6965],\n",
      "        [  809.6060],\n",
      "        [  806.8277],\n",
      "        [  798.4698],\n",
      "        [  791.3391],\n",
      "        [  810.8304],\n",
      "        [  778.5077],\n",
      "        [  796.3260],\n",
      "        [  832.1677],\n",
      "        [  788.4456],\n",
      "        [  768.8158],\n",
      "        [57106.8086],\n",
      "        [  772.2101],\n",
      "        [  804.3615],\n",
      "        [  764.6477],\n",
      "        [  784.6812],\n",
      "        [  763.3411],\n",
      "        [  766.0232],\n",
      "        [  790.1207],\n",
      "        [  799.0494],\n",
      "        [  787.9156],\n",
      "        [  806.0548],\n",
      "        [  778.1108],\n",
      "        [  785.3221],\n",
      "        [  783.5950],\n",
      "        [  835.1037],\n",
      "        [  765.6794],\n",
      "        [  810.7184],\n",
      "        [  821.1136],\n",
      "        [  770.1725],\n",
      "        [  775.0412],\n",
      "        [  771.6040],\n",
      "        [  777.8672],\n",
      "        [  779.9311],\n",
      "        [  820.1505],\n",
      "        [  761.2339],\n",
      "        [  803.5519],\n",
      "        [  768.6036],\n",
      "        [  779.9783],\n",
      "        [  770.0021],\n",
      "        [  797.9078],\n",
      "        [  755.3407],\n",
      "        [  766.2592],\n",
      "        [  827.7405],\n",
      "        [  795.8478],\n",
      "        [  785.2402],\n",
      "        [  758.3049],\n",
      "        [  802.0842],\n",
      "        [  814.3064],\n",
      "        [  761.0035],\n",
      "        [  766.9111],\n",
      "        [  812.1521],\n",
      "        [  750.8465],\n",
      "        [  792.1935],\n",
      "        [  803.0080],\n",
      "        [  762.3729],\n",
      "        [  786.2501],\n",
      "        [  792.0964],\n",
      "        [  766.1378],\n",
      "        [  792.7881],\n",
      "        [  763.6499],\n",
      "        [  937.8793],\n",
      "        [  783.1671],\n",
      "        [  758.0159],\n",
      "        [  764.9819],\n",
      "        [  810.9800],\n",
      "        [  855.8254],\n",
      "        [  785.1608],\n",
      "        [  773.5486],\n",
      "        [  794.1072],\n",
      "        [  774.6730],\n",
      "        [  767.8488],\n",
      "        [  791.9973],\n",
      "        [  833.9449],\n",
      "        [  760.6949],\n",
      "        [  762.8863],\n",
      "        [  753.1869],\n",
      "        [  777.1210],\n",
      "        [  797.6230],\n",
      "        [  779.5276],\n",
      "        [  839.5708],\n",
      "        [  764.1663],\n",
      "        [  769.9489],\n",
      "        [  771.8596],\n",
      "        [  780.1292],\n",
      "        [  795.4515],\n",
      "        [  806.8898],\n",
      "        [  821.2346],\n",
      "        [  812.9426],\n",
      "        [  799.9821],\n",
      "        [  829.6230],\n",
      "        [  816.6943],\n",
      "        [  815.0185],\n",
      "        [  830.5722],\n",
      "        [  821.3765],\n",
      "        [  813.3336],\n",
      "        [  795.0901],\n",
      "        [  810.9636],\n",
      "        [  812.9327],\n",
      "        [  812.2194],\n",
      "        [  834.6155],\n",
      "        [  815.3160],\n",
      "        [  804.8420],\n",
      "        [  806.5303],\n",
      "        [  827.4988],\n",
      "        [  816.6794],\n",
      "        [  857.9254],\n",
      "        [  830.8001],\n",
      "        [  840.4073],\n",
      "        [  813.8218],\n",
      "        [  849.8508],\n",
      "        [  826.5039],\n",
      "        [  973.4951],\n",
      "        [  808.7260],\n",
      "        [  818.1539],\n",
      "        [  795.2195],\n",
      "        [  830.0165],\n",
      "        [  816.7936],\n",
      "        [  825.1058],\n",
      "        [  830.8284],\n",
      "        [  818.0099],\n",
      "        [  867.5550],\n",
      "        [  818.3475],\n",
      "        [  776.1226],\n",
      "        [  801.8471],\n",
      "        [  809.9457],\n",
      "        [  806.3436],\n",
      "        [  815.3969],\n",
      "        [  809.4655],\n",
      "        [  799.5219],\n",
      "        [  815.6962],\n",
      "        [  823.8447],\n",
      "        [  818.3511],\n",
      "        [  806.0131],\n",
      "        [  795.8275],\n",
      "        [  824.3353],\n",
      "        [  789.1041],\n",
      "        [  843.6019],\n",
      "        [  814.5337],\n",
      "        [  841.4551],\n",
      "        [  838.0093],\n",
      "        [  820.0796],\n",
      "        [  822.0267],\n",
      "        [  828.6340],\n",
      "        [  812.1055],\n",
      "        [  865.8877],\n",
      "        [  819.8660],\n",
      "        [  800.4992],\n",
      "        [  784.8898],\n",
      "        [  801.7883],\n",
      "        [  795.4930],\n",
      "        [  807.3813],\n",
      "        [  835.6418],\n",
      "        [  835.5045],\n",
      "        [  803.2473],\n",
      "        [  783.5770],\n",
      "        [  833.9913],\n",
      "        [  795.2466],\n",
      "        [  808.2333],\n",
      "        [  786.5399],\n",
      "        [  804.5130],\n",
      "        [  860.5626],\n",
      "        [  806.8822],\n",
      "        [  792.5734],\n",
      "        [  843.3971],\n",
      "        [  796.0011],\n",
      "        [  822.9874],\n",
      "        [  824.6841],\n",
      "        [  824.7452],\n",
      "        [  823.1350],\n",
      "        [  766.7344],\n",
      "        [  795.8504],\n",
      "        [  789.0190],\n",
      "        [  829.1746],\n",
      "        [  781.2130],\n",
      "        [  795.4064],\n",
      "        [  798.0364],\n",
      "        [  811.3649]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test = torch.from_numpy(np.loadtxt(\"./data/embed_testvf.csv\", skiprows=1, dtype=np.float32, delimiter=\",\")).to(device)\n",
    "    out = model(test)\n",
    "    torch.set_printoptions(threshold=10000, sci_mode=False)\n",
    "    print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
